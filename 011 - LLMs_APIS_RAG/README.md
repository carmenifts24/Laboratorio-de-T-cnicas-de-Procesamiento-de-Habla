Análisis y Aplicación de APIs con LLMs y RAG
Descripción

Esta clase está dedicada a la exploración y aplicación práctica de APIs basadas en Modelos de Lenguaje de Gran Escala (LLMs), incluyendo ChatGPT, Gemini y arquitecturas RAG (Retrieval-Augmented Generation). A través de diversos notebooks, se desarrollan ejemplos que van desde el uso básico de APIs hasta la construcción de sistemas completos de recuperación y generación de información.

El objetivo de la actividad fue comprender cómo los LLMs pueden integrarse en flujos de trabajo reales mediante interfaces programáticas (APIs), mejorando tareas típicas de Procesamiento de Lenguaje Natural (PLN), como generación de texto, clasificación, búsqueda inteligente y sumarización. Además, se exploraron bases vectoriales, uso local de modelos con Ollama y búsqueda web contextualizada.

Información General

Tipo: NLP con APIs y LLMs

Cantidad de notebooks: 10 archivos Jupyter

Plataformas exploradas: OpenAI (ChatGPT), Google Gemini, Ollama, Hugging Face

Tareas realizadas: LLM básico, RAG, vector stores, web search, tareas NLP

Contenidos por archivo

01_Introduccion_APIs_LLMs.ipynb: Introducción al uso de APIs con LLMs.

02_ChatGPT_Conceptos_Basicos.ipynb: Envío de prompts y tareas comunes con ChatGPT desde código.

03_Gemini_API_Tareas_NLP.ipynb: Exploración de Gemini API y tareas de clasificación/resumen.

04_Carga_Documentos_RAG.ipynb: Carga de documentos para sistemas RAG.

05_Bases_Datos_Vectoriales.ipynb: Indexado y consulta en bases vectoriales para recuperación.

06_Sistema_RAG_Completo.ipynb: Integración de recuperación y generación (pipeline completo).

07_Ollama_LLMs_Locales.ipynb: Uso de LLMs de forma local con Ollama.

08_Busqueda_Web_Actualizada.ipynb: Consulta web dinámica usando LLMs.

06_Sumarizacion_Aplicada.ipynb: Técnicas aplicadas de sumarización con LLMs.

introduccion-a-hugging-face.ipynb: Primeros pasos con Hugging Face y su ecosistema de modelos.

Tecnologías y Librerías Usadas

Python 3.x

openai, google.generativeai, langchain, chromadb, faiss, llama-index

transformers, datasets, huggingface_hub

gradio, pandas, numpy, scikit-learn

Instrucciones de Uso

Clonar este repositorio.

Instalar dependencias necesarias (ver requirements.txt).

Explorar cada notebook de forma secuencial.

Para algunos notebooks es necesario contar con API keys de OpenAI y Gemini.

Para el uso de Ollama, es necesario instalarlo previamente en tu sistema operativo.

Resultados Esperados

Comprensión del flujo completo para usar LLMs mediante APIs.

Capacidad de construir sistemas RAG funcionales.

Uso efectivo de herramientas modernas como Hugging Face, LangChain, y bases vectoriales.

Aplicación de sumarización, búsqueda web y generación local de texto.