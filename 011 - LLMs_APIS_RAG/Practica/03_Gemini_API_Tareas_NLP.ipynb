{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5ZVm6CIouwgF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b88c72c-ff2f-49ba-a424-041240d6ee81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.5/260.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -U -q google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Procesamiento de Lenguaje Natural con Google Gemini API\n",
        "Este script demuestra diversas aplicaciones de Procesamiento de Lenguaje Natural (PLN) utilizando el modelo Gemini de Google a través de la librería `google-generativeai`."
      ],
      "metadata": {
        "id": "KvvIHZvXyE2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "0xS2NWpqvWHX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "cliente = genai.Client(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "sL2CGPN7vvHj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definición del texto de entrada"
      ],
      "metadata": {
        "id": "Cy_bZVjVyTbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto base que utilizaremos para todos los ejemplos.\n",
        "\n",
        "text_to_process = \"\"\"Estimado Amazon, la semana pasada pedí una figura de acción de Optimus Prime\n",
        "en su tienda en línea en Alemania. Desafortunadamente, cuando abrí el paquete,\n",
        "descubrí con horror que me habían enviado una figura de acción de Megatron\n",
        "en su lugar. Como enemigo de toda la vida de los Decepticons, espero que pueda\n",
        "entender mi dilema. Para resolver el problema, exijo un cambio de Megatron por\n",
        "la figura de Optimus Prime que pedí. Adjunto copias de mis registros relativos\n",
        "a esta compra. Espero tener noticias suyas pronto. Atentamente, Bumblebee.\"\"\"\n",
        "\n",
        "print(\"\\nTexto de entrada definido.\")"
      ],
      "metadata": {
        "id": "_NwHWVYpv_Ji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "840db382-98fd-4422-ae46-a5a23d7dfb11"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Texto de entrada definido.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID = \"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-05-20\",\"gemini-2.5-pro-preview-05-06\"] {\"allow-input\":true, isTemplate: true}"
      ],
      "metadata": {
        "id": "msa42Srs1Mci"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Sumarizacion"
      ],
      "metadata": {
        "id": "nR1SRBxf1Sma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pregunta = f\"\"\"Sumariza el siguiente texto en dos oraciones de rapida lectura\n",
        "\n",
        "Texto: {text_to_process}\n",
        "\"\"\"\n",
        "\n",
        "respuesta = cliente.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[pregunta] # Pasa la pregunta como contenido\n",
        ")\n",
        "print(respuesta.text)"
      ],
      "metadata": {
        "id": "zjLIg2OZ1Pby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68143f4a-32bc-4ea2-a019-0ea5910e04dd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bumblebee se queja a Amazon porque en lugar de su figura de Optimus Prime, recibió una de Megatron, su archienemigo. Exige que le cambien la figura incorrecta por la que originalmente ordenó.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Clasificación de Sentimiento"
      ],
      "metadata": {
        "id": "A0XQRDI01INu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pregunta = f\"\"\"Clasificá el siguiente texto como positivo, negativo o neutral y explicá por qué:\n",
        "\n",
        "Texto: {text_to_process}\n",
        "\"\"\"\n",
        "\n",
        "respuesta = cliente.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[pregunta] # Pasa la pregunta como contenido\n",
        ")\n",
        "print(respuesta.text)"
      ],
      "metadata": {
        "id": "w59q68sb0og-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c39d3356-5c83-40ed-eea4-5a63b106896f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El texto es **negativo**.\n",
            "\n",
            "Aquí te explico por qué:\n",
            "\n",
            "*   **Expresión de frustración:** El autor usa palabras como \"horror\" y \"desafortunadamente\" para expresar su decepción por recibir el producto incorrecto.\n",
            "*   **Problema con el pedido:** El autor no recibió lo que ordenó, lo que es un problema y una causa de insatisfacción.\n",
            "*   **Exigencia de una solución:** El autor \"exige\" un cambio, lo que implica que está insatisfecho y espera una rectificación.\n",
            "*   **Tono de queja:** Aunque el tono es educado (usa \"Estimado\" y \"Atentamente\"), el propósito principal del mensaje es quejarse de un error y solicitar una corrección.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Reconocimiento de Entidades Nombradas (NER)"
      ],
      "metadata": {
        "id": "Eyjbk9Ij1mlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"Extraé todas las entidades nombradas del siguiente texto (personas, organizaciones, lugares, objetos) y clasificálas:\n",
        "\n",
        "Texto: {text_to_process}\n",
        "\"\"\"\n",
        "\n",
        "respuesta = cliente.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[prompt] # Pasa la pregunta como contenido\n",
        ")\n",
        "print(respuesta.text)"
      ],
      "metadata": {
        "id": "0ZO0owXo1nqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2636dc20-e255-4c82-8a65-cccab9645517"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aquí están las entidades nombradas extraídas del texto y clasificadas:\n",
            "\n",
            "*   **Organización:**\n",
            "    *   Amazon\n",
            "    *   Decepticons\n",
            "*   **Persona:**\n",
            "    *   Bumblebee\n",
            "*   **Objeto:**\n",
            "    *   Optimus Prime (figura de acción)\n",
            "    *   Megatron (figura de acción)\n",
            "*   **Lugar:**\n",
            "    *   Alemania\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Respuesta a preguntas (Question Answering)"
      ],
      "metadata": {
        "id": "R7nLX8XA2ARy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pregunta = \"¿Qué producto recibió el cliente?\"\n",
        "contexto = text_to_process\n",
        "\n",
        "prompt = f\"\"\"Respondé la siguiente pregunta basada en el texto:\n",
        "\n",
        "Texto: {contexto}\n",
        "Pregunta: {pregunta}\n",
        "\"\"\"\n",
        "\n",
        "respuesta = cliente.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[contexto, pregunta] # Pasa la pregunta como contenido\n",
        ")\n",
        "print(respuesta.text)\n"
      ],
      "metadata": {
        "id": "_OJB5YkV2B0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74e024fe-703b-4033-90ca-238960410692"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El cliente recibió una figura de acción de **Megatron**.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Resumen automático"
      ],
      "metadata": {
        "id": "teUpLbTm2iah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"Resumí el siguiente texto en no más de 3 líneas:\n",
        "\n",
        "Texto: {text_to_process}\n",
        "\"\"\"\n",
        "\n",
        "respuesta = cliente.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[prompt] # Pasa la pregunta como contenido\n",
        ")\n",
        "print(respuesta.text)\n"
      ],
      "metadata": {
        "id": "eU1ntrhI2iIC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb50b348-b418-46c9-fcd1-e738695e7355"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bumblebee recibió por error una figura de Megatron en lugar de la figura de Optimus Prime que ordenó en Amazon Alemania. Exige un cambio por el artículo correcto y adjunta la documentación de su pedido. Espera una pronta respuesta.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. Traducción (Español a Inglés)"
      ],
      "metadata": {
        "id": "tnd7hnBo254-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"Traducí al inglés este texto:\n",
        "\n",
        "Texto: {text_to_process}\n",
        "\"\"\"\n",
        "\n",
        "respuesta = cliente.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[prompt] # Pasa la pregunta como contenido\n",
        ")\n",
        "print(respuesta.text)\n"
      ],
      "metadata": {
        "id": "txSjXi-w2zOL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a16d8d26-08af-4c31-f7ef-789ed8ac5b91"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here's the translated text:\n",
            "\n",
            "Dear Amazon,\n",
            "\n",
            "Last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent a Megatron action figure instead. As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve this issue, I demand an exchange of the Megatron figure for the Optimus Prime figure that I ordered. I have attached copies of my records pertaining to this purchase. I look forward to hearing from you soon.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "Bumblebee\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7. Generación de respuesta (como atención al cliente)"
      ],
      "metadata": {
        "id": "n2ODoTLy3Cp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "respuesta_inicial = \"Estimado cliente, lamentamos mucho lo ocurrido con su pedido. \"\n",
        "\n",
        "prompt = f\"\"\"{text_to_process}\n",
        "\n",
        "Redactá una respuesta del servicio de atención al cliente que comience así:\n",
        "\n",
        "\"{respuesta_inicial}\"\n",
        "\n",
        "Cuya extension no supere las 4 lineas.\n",
        "\"\"\"\n",
        "\n",
        "respuesta = cliente.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[prompt] # Pasa la pregunta como contenido\n",
        ")\n",
        "print(respuesta.text)"
      ],
      "metadata": {
        "id": "WmAhcje23CTG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4232899-9c30-4777-dce9-db92e4ac13b7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimado cliente, lamentamos mucho lo ocurrido con su pedido. Entendemos su frustración al recibir a Megatron en lugar de Optimus Prime. Le gestionaremos el envío de la figura correcta de Optimus Prime de inmediato y le proporcionaremos una etiqueta de devolución gratuita para Megatron. Por favor, revise su correo electrónico para más detalles.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8. Clasificación Zero-Shot (sin entrenamiento previo)"
      ],
      "metadata": {
        "id": "dtVjz8gr3VGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "etiquetas = [\"queja\", \"elogio\", \"consulta\", \"pedido\", \"agradecimiento\"]\n",
        "\n",
        "prompt = f\"\"\"Clasificá el siguiente texto en una de estas categorías: {', '.join(etiquetas)}. Justificá tu elección.\n",
        "\n",
        "Texto: {text_to_process}\n",
        "\"\"\"\n",
        "\n",
        "respuesta = cliente.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[prompt] # Pasa la pregunta como contenido\n",
        ")\n",
        "print(respuesta.text)\n"
      ],
      "metadata": {
        "id": "UtHlUvEy3URy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f864909-4cda-4c57-933d-f6b8c3fd2855"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La categoría del texto es **queja**.\n",
            "\n",
            "**Justificación:**\n",
            "\n",
            "El texto presenta claramente una **insatisfacción** con el servicio recibido. Bumblebee (el remitente) está expresando su disgusto por haber recibido un producto incorrecto (Megatron en lugar de Optimus Prime).  Utiliza palabras como \"horror\" y \"dilema\" para enfatizar su frustración.  Además, **exige** una solución (el cambio de Megatron por Optimus Prime), lo que es una característica típica de una queja.  No es un elogio porque no expresa satisfacción ni admiración. No es una consulta porque no busca información. No es un pedido en el sentido de una nueva solicitud, sino más bien la corrección de un pedido previo. No es un agradecimiento, ya que no muestra gratitud por ningún servicio prestado.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EJERCICIO\n",
        "\n",
        "Escribí un texto corto sobre una experiencia personal en un transporte público en Buenos Aires.\n",
        "\n",
        "Luego, generá:\n",
        "\n",
        "- Un resumen.\n",
        "- Una clasificación de sentimiento.\n",
        "- Una lista de entidades nombradas."
      ],
      "metadata": {
        "id": "nOPQ22a63k0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# EJERCICIO FINAL – NLP con Gemini\n",
        "# ============================================================\n",
        "\n",
        "from google.generativeai import GenerativeModel\n",
        "\n",
        "modelo = GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# 1) Texto original\n",
        "texto = \"\"\"\n",
        "La semana pasada viajé en la línea 59 desde Plaza Italia hacia Constitución.\n",
        "El colectivo venía muy lleno y casi no había espacio para moverse.\n",
        "En una de las paradas subió una mujer mayor y, de manera espontánea,\n",
        "varias personas se ofrecieron a cederle el asiento.\n",
        "Fue un gesto simple, pero generó un clima de respeto y amabilidad\n",
        "que contrastó con el ritmo acelerado de la ciudad.\n",
        "\"\"\"\n",
        "\n",
        "# 2) Prompt para generar resumen, sentimiento y entidades\n",
        "prompt = f\"\"\"\n",
        "Tomá el siguiente texto y generá:\n",
        "\n",
        "1. Un resumen.\n",
        "2. Una clasificación de sentimiento (positivo, negativo o neutro) con una breve explicación.\n",
        "3. Una lista de entidades nombradas presentes en el texto (lugares, personas, organizaciones, etc.).\n",
        "\n",
        "TEXTO:\n",
        "\\\"\\\"\\\"{texto}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "\n",
        "respuesta = cliente.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[prompt] # Pasa la pregunta como contenido\n",
        ")\n",
        "\n",
        "print(\"=== TEXTO ORIGINAL ===\\n\")\n",
        "print(texto)\n",
        "\n",
        "print(\"\\n=== RESPUESTA DEL MODELO ===\\n\")\n",
        "print(respuesta.text)"
      ],
      "metadata": {
        "id": "q4tabbo45G6a",
        "outputId": "bc274db5-7bd6-4dd1-cd74-1785fe83fb16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TEXTO ORIGINAL ===\n",
            "\n",
            "\n",
            "La semana pasada viajé en la línea 59 desde Plaza Italia hacia Constitución. \n",
            "El colectivo venía muy lleno y casi no había espacio para moverse. \n",
            "En una de las paradas subió una mujer mayor y, de manera espontánea, \n",
            "varias personas se ofrecieron a cederle el asiento. \n",
            "Fue un gesto simple, pero generó un clima de respeto y amabilidad \n",
            "que contrastó con el ritmo acelerado de la ciudad.\n",
            "\n",
            "\n",
            "=== RESPUESTA DEL MODELO ===\n",
            "\n",
            "¡Aquí tienes el análisis del texto!\n",
            "\n",
            "**1. Resumen:**\n",
            "\n",
            "El autor relata un viaje en colectivo (línea 59) desde Plaza Italia a Constitución. A pesar de la aglomeración, destaca un acto de amabilidad cuando varios pasajeros ofrecieron su asiento a una mujer mayor, creando un ambiente positivo en contraste con el ritmo agitado de la ciudad.\n",
            "\n",
            "**2. Clasificación de sentimiento:**\n",
            "\n",
            "*   **Sentimiento:** Positivo\n",
            "*   **Explicación:** El texto, aunque describe una situación común como un viaje en transporte público lleno, se centra en un acto de amabilidad y respeto que generó un ambiente positivo. La frase \"un clima de respeto y amabilidad\" es un claro indicador de sentimiento positivo. El contraste con el \"ritmo acelerado de la ciudad\" refuerza la apreciación del autor por este gesto.\n",
            "\n",
            "**3. Lista de Entidades Nombradas:**\n",
            "\n",
            "*   **Lugares:**\n",
            "    *   Plaza Italia\n",
            "    *   Constitución\n",
            "*   **Organizaciones:**\n",
            "    *   Línea 59\n",
            "*   **Personas:**\n",
            "    *   Mujer mayor (mencionada pero no identificada por nombre)\n",
            "    *   El autor (implícito, quien narra la experiencia)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}